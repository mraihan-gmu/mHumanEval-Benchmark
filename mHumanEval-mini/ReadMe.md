# **mHumanEval-mini Overview** ðŸŒŸ

**mHumanEval-mini** is a streamlined subset designed for rapid evaluation of a Code LLM's multilingual capabilities. 

## Key Features âœ¨

- **Total Prompts**: 204 
- **Languages**: 204 
- **Prompts per Language**: 1

| **Feature**          | **Description**                                                    |
|----------------------|--------------------------------------------------------------------|
| **Total Prompts**    | 204                                                                |
| **Languages**        | 204                                                                |
| **Prompts per NL**   | 1                                                                  |

## Purpose ðŸŽ¯

**mHumanEval-mini** is intended for quick evaluation of a Code LLM's multilinguality. It provides a concise yet comprehensive benchmark:

- **Quick Evaluation**: With just 204 prompts, it allows for a rapid assessment.
- **Multilingual Test**: Each prompt represents a unique natural language (NL), ensuring a broad language coverage.

## Why mHumanEval-mini? ðŸš€

While **mHumanEval** includes a massive 33,456 prompts, **mHumanEval-mini** serves as a practical alternative for quick testing:

- **Efficient**: Ideal for situations where time and resources are limited.
- **Comprehensive**: Despite its smaller size, it still offers a robust evaluation framework.

**mHumanEval-mini** is your go-to choice for a quick litmus test of a Code LLMâ€™s multilingual performance!

