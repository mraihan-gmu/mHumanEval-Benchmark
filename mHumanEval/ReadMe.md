# **mHumanEval Benchmark**

**Here, we have the original mHumanEval benchmark.**

### Overview

| **Total Prompts** | **Natural Languages** | **Prompts per Language** |
|-------------------|-----------------------|--------------------------|
| **33,456**        | **204**               | **164**                  |

### Key Details

- **Canonical Solutions**: Provided in **Python**.
- **Language Codes**: We used **Flores-200** codes.

### Prompts Distribution

<font color="blue">**Prompts per Language**</font>: 164
<font color="green">**Total Languages**</font>: 204

